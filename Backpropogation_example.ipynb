{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to demonstrate how backpropogation works in neural network \n",
    "# backpropogation is technique to update weights and bias to minimize the loss\n",
    "# diffrentiate loss with respect to weight or bias\n",
    "# Reference: https://hmkcode.com/ai/backpropagation-step-by-step/\n",
    "# we will take function y = 2x to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generated values\n",
    "data = []\n",
    "for i in range(100):\n",
    "    x = random.uniform(1, 100)\n",
    "    y = 2*x\n",
    "    data.append([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer => 1 neuron \n",
    "# hidden layer => 2 neuron \n",
    "# output layer => 1 neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 2\n",
    "        self.w3 = 3\n",
    "        self.w4 = 2\n",
    "        self.learning_rate = 0.00001  #try different learning rate if model is not working\n",
    "        self.output = float(\"inf\")\n",
    "        self.h1 = []\n",
    "        \n",
    "    def forward_propogation(self, x):\n",
    "        l1 = [[self.w1],[self.w2]]\n",
    "        i = [x]\n",
    "        h1 = np.dot(l1, i) # [h11, h12]\n",
    "        self.h1 = h1\n",
    "        l2 = [self.w3, self.w4]\n",
    "        output = np.dot(l2, h1)\n",
    "        self.output = output\n",
    "        print(output)\n",
    "        \n",
    "    def backward_propogation(self, y):\n",
    "        loss = (self.output - y)\n",
    "        print(\"loss=\", loss)\n",
    "        \n",
    "        # loss for w4\n",
    "        # using chain rule\n",
    "        # d(loss)/d(w4) = d(loss)/d(output) * d(output)/d(w2)\n",
    "        # using MSE \n",
    "        # loss = 1/2(output - y)**2\n",
    "        # d(loss)/d(output) = (output - y)\n",
    "        # d(self.output)/d(w4) = (w4*h12 + w3*h11)/d(w4) = h12\n",
    "\n",
    "        error_w4 = loss*self.h1[1]\n",
    "        #updating the weights \n",
    "        self.w4 = self.w4 - self.learning_rate*error_w4\n",
    "        \n",
    "        #similarly for w3\n",
    "        error_w3 = loss*self.h1[0]\n",
    "        self.w3 = self.w3 - self.learning_rate*error_w3\n",
    "        \n",
    "        # loss for w2\n",
    "        # d(loss)/d(w2) = d(loss)/d(output) * d(output)/d(h11) * d(h11)/d(w2)\n",
    "        # d(loss)/output = (output - y)\n",
    "        # d(output)/d(h11) = (h11*w3 + h12*w4)/d(h11) = w4\n",
    "        # d(h11)/d(w2) = (i*w2)/d(w2) = i\n",
    "        error_w2 = loss*self.w4*i\n",
    "        self.w2 = self.w2 - self.learning_rate*error_w2\n",
    "        \n",
    "        #similarly for w1\n",
    "        error_w1 = loss*self.w3*i\n",
    "        self.w1 = self.w1 - self.learning_rate*error_w1\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.65818673944858\n",
      "loss= 156.18441909960612\n",
      "442.954600115183\n",
      "loss= 260.28315293202024\n",
      "123.70155656544938\n",
      "loss= -45.95210236353972\n",
      "168.5847398838251\n",
      "loss= -0.25027048660160744\n",
      "2.0978854245329197\n",
      "loss= 1.9013255982969213e-06\n",
      "30.583110479323032\n",
      "loss= 2.74199722518631e-05\n",
      "59.97507522800323\n",
      "loss= 4.5126389544236645e-05\n",
      "37.95616078336525\n",
      "loss= 1.9310331083488563e-05\n",
      "113.9116241690823\n",
      "loss= 4.6310171697427904e-05\n",
      "190.59424412656637\n",
      "loss= 2.7519315921153975e-05\n",
      "109.840713300142\n",
      "loss= -2.3747878259428035e-06\n",
      "36.24773721647894\n",
      "loss= -2.9808857959778834e-07\n",
      "133.90738960244772\n",
      "loss= -8.902620436401776e-07\n",
      "125.28944689165172\n",
      "loss= -1.907415594359918e-07\n",
      "36.66316701926675\n",
      "loss= -1.5842971379242954e-08\n",
      "5.562956602642123\n",
      "loss= -1.9379422511178745e-09\n",
      "39.837915055447006\n",
      "loss= -1.3481624705491413e-08\n",
      "71.3521196964617\n",
      "loss= -1.90461122429042e-08\n",
      "11.657200185022534\n",
      "loss= -1.9005845786068676e-09\n",
      "58.030106851845645\n",
      "loss= -8.891490210771735e-09\n",
      "15.678663184362101\n",
      "loss= -1.6508856504060532e-09\n",
      "162.08492594613483\n",
      "loss= -1.5679319176342688e-08\n",
      "82.06234216987137\n",
      "loss= -3.5423397548584035e-10\n",
      "67.1043069126988\n",
      "loss= -1.587920905876672e-10\n",
      "122.66492206076347\n",
      "loss= -1.844142616391764e-10\n",
      "173.3973747473345\n",
      "loss= -7.833023119019344e-11\n",
      "130.22590987679666\n",
      "loss= 1.9042545318370685e-12\n",
      "187.52789278785124\n",
      "loss= 6.821210263296962e-13\n",
      "171.80549018603094\n",
      "loss= -1.1368683772161603e-13\n",
      "178.55753549734126\n",
      "loss= 2.842170943040401e-14\n",
      "55.762718620095036\n",
      "loss= -7.105427357601002e-15\n",
      "144.57063518014004\n",
      "loss= 0.0\n",
      "143.0682382056076\n",
      "loss= 2.842170943040401e-14\n",
      "99.94972460287754\n",
      "loss= -1.4210854715202004e-14\n",
      "3.422643267204458\n",
      "loss= -4.440892098500626e-16\n",
      "59.395068179253045\n",
      "loss= -7.105427357601002e-15\n",
      "45.03826865737948\n",
      "loss= 0.0\n",
      "191.69570821136256\n",
      "loss= 0.0\n",
      "179.1087828823657\n",
      "loss= 0.0\n",
      "156.8659094133369\n",
      "loss= 0.0\n",
      "118.83707999297596\n",
      "loss= 0.0\n",
      "114.45102559688148\n",
      "loss= 0.0\n",
      "175.02577619626578\n",
      "loss= 0.0\n",
      "141.32724096071252\n",
      "loss= 0.0\n",
      "165.36769964910184\n",
      "loss= 0.0\n",
      "115.54413567781174\n",
      "loss= 0.0\n",
      "181.95360671339688\n",
      "loss= -2.842170943040401e-14\n",
      "31.170491912787515\n",
      "loss= 3.552713678800501e-15\n",
      "130.14292495310053\n",
      "loss= 0.0\n",
      "96.96214865996131\n",
      "loss= 0.0\n",
      "190.4520278739862\n",
      "loss= 2.842170943040401e-14\n",
      "8.822883287153854\n",
      "loss= -1.7763568394002505e-15\n",
      "162.98300490492628\n",
      "loss= -2.842170943040401e-14\n",
      "67.3564166013342\n",
      "loss= 0.0\n",
      "139.27850252506863\n",
      "loss= 2.842170943040401e-14\n",
      "90.8009572665821\n",
      "loss= 0.0\n",
      "95.52395141539262\n",
      "loss= 0.0\n",
      "13.96969751847651\n",
      "loss= 0.0\n",
      "179.08446037166865\n",
      "loss= 0.0\n",
      "135.0166906351435\n",
      "loss= -2.842170943040401e-14\n",
      "143.58795482394888\n",
      "loss= 0.0\n",
      "182.7756391364248\n",
      "loss= 2.842170943040401e-14\n",
      "93.20612722386188\n",
      "loss= -1.4210854715202004e-14\n",
      "97.37074409828432\n",
      "loss= 0.0\n",
      "62.27325098414053\n",
      "loss= 0.0\n",
      "22.04791188366694\n",
      "loss= 0.0\n",
      "89.40098144235762\n",
      "loss= 0.0\n",
      "82.49884837573013\n",
      "loss= 0.0\n",
      "157.71752830142086\n",
      "loss= 0.0\n",
      "52.7518041603506\n",
      "loss= 7.105427357601002e-15\n",
      "110.44409045449105\n",
      "loss= 0.0\n",
      "68.95008424423548\n",
      "loss= 1.4210854715202004e-14\n",
      "120.28118667756705\n",
      "loss= -1.4210854715202004e-14\n",
      "100.06745020042626\n",
      "loss= 0.0\n",
      "144.92546370077122\n",
      "loss= 0.0\n",
      "163.84793190595713\n",
      "loss= 0.0\n",
      "192.2462692426758\n",
      "loss= 0.0\n",
      "19.51833205571682\n",
      "loss= 0.0\n",
      "134.18537209626186\n",
      "loss= 0.0\n",
      "152.94222151954455\n",
      "loss= 0.0\n",
      "114.36110478667855\n",
      "loss= -1.4210854715202004e-14\n",
      "28.251185570911556\n",
      "loss= 0.0\n",
      "114.88941171578438\n",
      "loss= -1.4210854715202004e-14\n",
      "176.656844913611\n",
      "loss= 2.842170943040401e-14\n",
      "16.51056542185006\n",
      "loss= 0.0\n",
      "99.15391982627425\n",
      "loss= 0.0\n",
      "132.08394294400756\n",
      "loss= 0.0\n",
      "130.74888396284726\n",
      "loss= 2.842170943040401e-14\n",
      "102.681378875387\n",
      "loss= 0.0\n",
      "110.23291478865636\n",
      "loss= 0.0\n",
      "81.11231115703173\n",
      "loss= -1.4210854715202004e-14\n",
      "109.32381086155813\n",
      "loss= -1.4210854715202004e-14\n",
      "125.57696825197618\n",
      "loss= 2.842170943040401e-14\n",
      "120.01886354840745\n",
      "loss= 1.4210854715202004e-14\n",
      "101.46827550183845\n",
      "loss= -1.4210854715202004e-14\n",
      "54.46694980083795\n",
      "loss= -7.105427357601002e-15\n",
      "149.6120111421493\n",
      "loss= 0.0\n",
      "148.9327317960969\n",
      "loss= 0.0\n",
      "58.140614208106015\n",
      "loss= 0.0\n",
      "186.658960206558\n",
      "loss= -5.684341886080802e-14\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "for x, y in data:\n",
    "    model.forward_propogation(x)\n",
    "    model.backward_propogation(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example shows that learning rate is really important\n",
    "# let's test our model with  some random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(100):\n",
    "    x = random.uniform(1, 1000)\n",
    "    test.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493.08006263472373\n",
      "986.1601252694476\n",
      " \n",
      "26.42357434371624\n",
      "52.847148687432494\n",
      " \n",
      "665.166412704804\n",
      "1330.3328254096082\n",
      " \n",
      "472.29482530559466\n",
      "944.5896506111894\n",
      " \n",
      "162.60352138701404\n",
      "325.20704277402814\n",
      " \n",
      "841.5297873307542\n",
      "1683.0595746615086\n",
      " \n",
      "597.6521199607672\n",
      "1195.3042399215349\n",
      " \n",
      "948.2743318620151\n",
      "1896.5486637240303\n",
      " \n",
      "532.4182891291317\n",
      "1064.8365782582637\n",
      " \n",
      "945.3551350684129\n",
      "1890.7102701368262\n",
      " \n",
      "754.0221514492575\n",
      "1508.0443028985153\n",
      " \n",
      "328.6473892289677\n",
      "657.2947784579355\n",
      " \n",
      "714.3215758278882\n",
      "1428.6431516557766\n",
      " \n",
      "214.0143464048964\n",
      "428.0286928097929\n",
      " \n",
      "402.63132969944195\n",
      "805.262659398884\n",
      " \n",
      "521.2638547563671\n",
      "1042.5277095127344\n",
      " \n",
      "789.4881830017334\n",
      "1578.976366003467\n",
      " \n",
      "458.1403931892773\n",
      "916.2807863785547\n",
      " \n",
      "356.1868741832369\n",
      "712.3737483664739\n",
      " \n",
      "315.68431966016044\n",
      "631.368639320321\n",
      " \n",
      "698.1162113193039\n",
      "1396.232422638608\n",
      " \n",
      "692.8623399278166\n",
      "1385.7246798556334\n",
      " \n",
      "660.1593738610202\n",
      "1320.3187477220406\n",
      " \n",
      "27.651528641422\n",
      "55.30305728284401\n",
      " \n",
      "853.6511186765111\n",
      "1707.3022373530225\n",
      " \n",
      "563.7012929716201\n",
      "1127.4025859432402\n",
      " \n",
      "792.7960350901175\n",
      "1585.5920701802352\n",
      " \n",
      "712.8552320687875\n",
      "1425.7104641375752\n",
      " \n",
      "513.9437765403652\n",
      "1027.8875530807304\n",
      " \n",
      "869.6278254062967\n",
      "1739.2556508125938\n",
      " \n",
      "974.8761247794877\n",
      "1949.7522495589756\n",
      " \n",
      "857.1092211272768\n",
      "1714.2184422545538\n",
      " \n",
      "68.15221755500927\n",
      "136.30443511001855\n",
      " \n",
      "811.0353769479775\n",
      "1622.070753895955\n",
      " \n",
      "201.7224368366275\n",
      "403.44487367325513\n",
      " \n",
      "792.9151606111077\n",
      "1585.8303212222156\n",
      " \n",
      "848.5145499164249\n",
      "1697.0290998328503\n",
      " \n",
      "693.4772218364485\n",
      "1386.9544436728972\n",
      " \n",
      "941.0468321250562\n",
      "1882.0936642501126\n",
      " \n",
      "181.58096432586495\n",
      "363.16192865172997\n",
      " \n",
      "3.383134554323897\n",
      "6.766269108647795\n",
      " \n",
      "799.8911999979678\n",
      "1599.7823999959355\n",
      " \n",
      "727.7105624655582\n",
      "1455.4211249311165\n",
      " \n",
      "127.06253069662267\n",
      "254.12506139324537\n",
      " \n",
      "372.3620296763436\n",
      "744.7240593526872\n",
      " \n",
      "366.8180067852125\n",
      "733.6360135704251\n",
      " \n",
      "664.5427035543237\n",
      "1329.0854071086476\n",
      " \n",
      "505.8630586206371\n",
      "1011.7261172412742\n",
      " \n",
      "305.54425129906366\n",
      "611.0885025981274\n",
      " \n",
      "395.65215645538495\n",
      "791.30431291077\n",
      " \n",
      "739.4310221721857\n",
      "1478.8620443443717\n",
      " \n",
      "158.27072621114564\n",
      "316.54145242229134\n",
      " \n",
      "639.8422970521934\n",
      "1279.684594104387\n",
      " \n",
      "176.4777496686276\n",
      "352.9554993372553\n",
      " \n",
      "100.24533180951354\n",
      "200.49066361902712\n",
      " \n",
      "484.1386273958144\n",
      "968.277254791629\n",
      " \n",
      "426.11221455422213\n",
      "852.2244291084444\n",
      " \n",
      "771.7932143751646\n",
      "1543.5864287503293\n",
      " \n",
      "723.961196243843\n",
      "1447.9223924876862\n",
      " \n",
      "273.8922553345241\n",
      "547.7845106690484\n",
      " \n",
      "778.5936316012294\n",
      "1557.187263202459\n",
      " \n",
      "503.0960091503403\n",
      "1006.1920183006807\n",
      " \n",
      "570.4393070191683\n",
      "1140.8786140383368\n",
      " \n",
      "534.4152879605642\n",
      "1068.8305759211287\n",
      " \n",
      "714.2859248564531\n",
      "1428.5718497129064\n",
      " \n",
      "468.15526431048914\n",
      "936.3105286209785\n",
      " \n",
      "490.7911790551874\n",
      "981.5823581103751\n",
      " \n",
      "809.9640190321398\n",
      "1619.9280380642801\n",
      " \n",
      "603.2149493463359\n",
      "1206.4298986926722\n",
      " \n",
      "82.63182821399576\n",
      "165.26365642799155\n",
      " \n",
      "590.6643611832844\n",
      "1181.328722366569\n",
      " \n",
      "839.7746929043473\n",
      "1679.549385808695\n",
      " \n",
      "800.0210632370547\n",
      "1600.0421264741094\n",
      " \n",
      "940.3984668241806\n",
      "1880.7969336483616\n",
      " \n",
      "107.10074119008252\n",
      "214.2014823801651\n",
      " \n",
      "479.3590393341236\n",
      "958.7180786682475\n",
      " \n",
      "443.1890307225585\n",
      "886.3780614451172\n",
      " \n",
      "981.782578382709\n",
      "1963.5651567654184\n",
      " \n",
      "222.27155255990792\n",
      "444.5431051198159\n",
      " \n",
      "572.7837231427707\n",
      "1145.5674462855416\n",
      " \n",
      "854.8556559361753\n",
      "1709.7113118723507\n",
      " \n",
      "719.313887626211\n",
      "1438.6277752524222\n",
      " \n",
      "25.79131259587289\n",
      "51.58262519174579\n",
      " \n",
      "868.8394948324772\n",
      "1737.6789896649548\n",
      " \n",
      "240.39922462938733\n",
      "480.79844925877467\n",
      " \n",
      "708.3343746186883\n",
      "1416.668749237377\n",
      " \n",
      "490.2903568413404\n",
      "980.5807136826808\n",
      " \n",
      "312.1355894752825\n",
      "624.2711789505651\n",
      " \n",
      "36.7732035567183\n",
      "73.54640711343662\n",
      " \n",
      "913.9900270144104\n",
      "1827.9800540288213\n",
      " \n",
      "485.05498904071777\n",
      "970.1099780814358\n",
      " \n",
      "494.83653693515083\n",
      "989.673073870302\n",
      " \n",
      "770.0389109156234\n",
      "1540.0778218312473\n",
      " \n",
      "816.4330832086587\n",
      "1632.8661664173173\n",
      " \n",
      "486.90161215204245\n",
      "973.8032243040851\n",
      " \n",
      "23.337520765930435\n",
      "46.67504153186087\n",
      " \n",
      "211.84025255616024\n",
      "423.6805051123205\n",
      " \n",
      "469.96160570388207\n",
      "939.9232114077643\n",
      " \n",
      "748.5427319887247\n",
      "1497.0854639774495\n",
      " \n",
      "369.62106299027755\n",
      "739.2421259805552\n",
      " \n",
      "pretty good!!\n"
     ]
    }
   ],
   "source": [
    "for t in test:\n",
    "    print(t)\n",
    "    model.forward_propogation(t)\n",
    "    print(\" \")\n",
    "print(\"pretty good!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
